{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n",
      "C:\\Users\\Natha\\AppData\\Local\\Temp\\ipykernel_2952\\2729243670.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  hist_df[var] = test[var].map(var_stats)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000516 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 180\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 178\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 182\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 183\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000392 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000490 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 196\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 178\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000473 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 180\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 188\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000482 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000554 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001055 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 264\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 178\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 182\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 212\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000497 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000540 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 180\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000410 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 205\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000669 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 178\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000482 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 197\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000471 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 180\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000421 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 182\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 179\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 204\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 179\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 180\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 183\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000542 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 179\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000556 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000493 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 197\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 220\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000633 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000521 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000506 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000328 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 199\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 179\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 198\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 195\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 178\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 194\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 184\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000528 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 179\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000410 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 187\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 321\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000483 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 178\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 228\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 179\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 174\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000496 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 179\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 184\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000336 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 187\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000345 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 184\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 179\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000511 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 178\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 182\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 180\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000526 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 260\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 179\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 208\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 182\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000413 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 201\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 174\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000547 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 174\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000328 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 200\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 174\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 244\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000370 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 184\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000326 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 196\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000345 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 184\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 178\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 278\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000485 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 178\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 180\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 191\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 191\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 183\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000343 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 174\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000571 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 179\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000524 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 174\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000539 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 178\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000547 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 180\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 219\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000533 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 180\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000550 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 179\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 196\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000343 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 208\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000331 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 219\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000520 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000515 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000579 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000497 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000513 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 182\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 195\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 179\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 185\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000328 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 247\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000576 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 183\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000497 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 179\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000535 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 180\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 182\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 192\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 178\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 174\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000539 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000519 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 174\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 238\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 187\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 178\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000539 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 178\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 178\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 216\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000563 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 179\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 219\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000560 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 180\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000565 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000513 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000493 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 183\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000518 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 182\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 182\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000497 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 196\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000497 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000548 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000548 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 178\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000413 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 192\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000507 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 180\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 180\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000345 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000519 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 180\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000344 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 187\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 194\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000571 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 180\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n",
      "[LightGBM] [Info] Number of positive: 20098, number of negative: 179902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000511 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 174\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100490 -> initscore=-2.191792\n",
      "[LightGBM] [Info] Start training from score -2.191792\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import logit\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Load the train and test datasets\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "train = train.drop('ID_code', axis = 1)\n",
    "\n",
    "test_id = test.ID_code\n",
    "test = test.drop('ID_code', axis = 1)\n",
    "\n",
    "correlations = train.drop(\"target\", axis = 1).corr().abs().unstack().sort_values(kind = \"quicksort\").reset_index()\n",
    "correlations = correlations[correlations['level_0'] != correlations['level_1']]\n",
    "\n",
    "variables = train.drop(\"target\", axis = 1).columns.values.tolist()\n",
    "corr_pre_res = np.zeros(len(variables))\n",
    "i = 0\n",
    "for var in variables:\n",
    "    corr_pre_res[i] = np.corrcoef(train[var], train[\"target\"])[0, 1]\n",
    "    i += 1\n",
    "\n",
    "corr_pre_res = abs(pd.DataFrame(corr_pre_res))\n",
    "corr_pre_res.columns = ['corr_pre_res']\n",
    "corr_pre_res.sort_values(by = 'corr_pre_res')\n",
    "\n",
    "# Define the features list (assuming that features start with 'var')\n",
    "features = [x for x in train.columns if x.startswith(\"var\")]\n",
    "\n",
    "# Create the hist_df DataFrame for value counts\n",
    "hist_df = pd.DataFrame()\n",
    "\n",
    "# Loop through each feature to calculate value counts\n",
    "for var in features:\n",
    "    # Concatenate the 'train' and 'test' series for the current feature\n",
    "    var_stats = pd.concat([train[var], test[var]]).value_counts()  # Use pd.concat() instead of append()\n",
    "\n",
    "    # Map the value counts to the 'test' data for the current variable\n",
    "    hist_df[var] = test[var].map(var_stats)\n",
    "\n",
    "    # Set values to 1 if the count of that value is greater than 1\n",
    "    hist_df[var] = hist_df[var] > 1\n",
    "\n",
    "# Continue with your model training and predictions\n",
    "ind = hist_df.sum(axis=1) != 200\n",
    "var_stats = {var: pd.concat([train[var], test[ind][var]]).value_counts() for var in features}\n",
    "\n",
    "pred = 0\n",
    "for var in features:\n",
    "    model = lgb.LGBMClassifier(**{'learning_rate': 0.05,\n",
    "                                  'max_bin': 165,\n",
    "                                  'max_depth': 5,\n",
    "                                  'min_child_samples': 150,\n",
    "                                  'min_child_weight': 0.1,\n",
    "                                  'min_split_gain': 0.0018,\n",
    "                                  'n_estimators': 41,\n",
    "                                  'num_leaves': 6,\n",
    "                                  'reg_alpha': 2.0,\n",
    "                                  'reg_lambda': 2.54,\n",
    "                                  'objective': 'binary',\n",
    "                                  'n_jobs': -1})\n",
    "    model = model.fit(np.hstack([train[var].values.reshape(-1, 1),\n",
    "                      train[var].map(var_stats[var]).values.reshape(-1, 1)]), train[\"target\"].values)\n",
    "    pred += logit(model.predict_proba(np.hstack([test[var].values.reshape(-1, 1),\n",
    "                  test[var].map(var_stats[var]).values.reshape(-1, 1)]))[:, 1])\n",
    "\n",
    "pd.DataFrame({\"ID_code\": test_id, \"target\": pred}).to_csv(\"Submission.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
